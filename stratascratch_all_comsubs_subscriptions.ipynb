{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get StrataScratch Subscribers with .subscribers() Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-auth\n",
    "!pip install google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Credentials From File...\n",
      "Refreshing Access Token...\n"
     ]
    }
   ],
   "source": [
    "credentials = None\n",
    "\n",
    "# token.pickle stores the user's credentials from previously successful logins\n",
    "if os.path.exists('token.pickle'):\n",
    "    print('Loading Credentials From File...')\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        credentials = pickle.load(token)\n",
    "\n",
    "# Google's Request\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "\n",
    "# If there are no valid credentials available, then either refresh the token or log in.\n",
    "if not credentials or not credentials.valid:\n",
    "    if credentials and credentials.expired and credentials.refresh_token:\n",
    "        print('Refreshing Access Token...')\n",
    "        credentials.refresh(Request())\n",
    "    else:\n",
    "        print('Fetching New Tokens...')\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'client_secrets.json',\n",
    "            scopes=[\n",
    "                'https://www.googleapis.com/auth/youtube.readonly'\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        flow.run_local_server(port=8080, prompt='consent')#,authorization_prompt_message='')\n",
    "        credentials = flow.credentials\n",
    "\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as f:\n",
    "            print('Saving Credentials for Future Use...')\n",
    "            pickle.dump(credentials, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get first response for sub/comms subscriptions that are allowed:\n",
    "def get_subcomms_subscriptions_first_response(channelId):\n",
    "        api_service_name = \"youtube\"\n",
    "        api_version = \"v3\"\n",
    "\n",
    "        youtube = googleapiclient.discovery.build(api_service_name, api_version, credentials=credentials)\n",
    "        request = youtube.subscriptions().list(part=\"snippet\",channelId=channelId)\n",
    "        # request = youtube.subscriptions().list(part=\"snippet,contentDetails\",pageToken='CLYHEAE', maxResults=maxResults,mySubscribers=True)\n",
    "        response = request.execute()\n",
    "        return response, request, youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subscriber_ids(df,response):\n",
    "    for sub in response['items']:\n",
    "        if sub['kind'] == 'youtube#subscription': \n",
    "            \n",
    "            response_kind =sub['kind']\n",
    "            publishedAt=sub['snippet']['publishedAt']\n",
    "            channel_title =sub['snippet']['title']\n",
    "            channel_description =sub['snippet']['description']\n",
    "            channelId = sub['snippet']['resourceId']['channelId']\n",
    "            sub_channelId = sub['snippet']['channelId']        \n",
    "\n",
    "            try:\n",
    "                if response['nextPageToken'] != None:\n",
    "                    pageToken = response['nextPageToken']\n",
    "                    df = df.append({'response_kind': response_kind, 'publishedAt':publishedAt, 'channel_title':channel_title,'channel_description':channel_description,'channelId':channelId,'sub_channelId':sub_channelId,'pageToken':pageToken},ignore_index=True)    \n",
    "            except:\n",
    "                #save data in pandas df\n",
    "                df = df.append({'response_kind': response_kind, 'publishedAt':publishedAt, 'channel_title':channel_title,'channelId':channelId,'sub_channelId':sub_channelId,'pageToken':'none'},ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subs_pagination(df,request,response,youtube):\n",
    "    while 1:\n",
    "        try:\n",
    "            request = youtube.subscriptions().list_next(previous_request=request, previous_response=response)\n",
    "            response = request.execute()\n",
    "            df = get_subscriber_ids(df,response)\n",
    "        \n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    return df,request,response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_csv('strata_unique_commenters_with_1k_of_subscribers.csv',low_memory=False)\n",
    "df_combo = pd.read_csv('all_ss_comsubs_combined.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n"
     ]
    }
   ],
   "source": [
    "start = 1218 #after monday morning run\n",
    "# start = last_user\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df length: 5\n",
      "user count: 1\n",
      "df length: 291\n",
      "user count: 2\n",
      "df length: 779\n",
      "user count: 3\n",
      "df length: 1063\n",
      "user count: 4\n",
      "df length: 1381\n",
      "user count: 5\n",
      "df length: 1540\n",
      "user count: 6\n",
      "df length: 1588\n",
      "user count: 7\n",
      "df length: 1773\n",
      "user count: 8\n",
      "df length: 1808\n",
      "user count: 9\n",
      "df length: 1854\n",
      "user count: 10\n",
      "df length: 1933\n",
      "user count: 11\n",
      "df length: 1966\n",
      "user count: 12\n",
      "df length: 2065\n",
      "user count: 13\n",
      "df length: 2213\n",
      "user count: 14\n",
      "df length: 2287\n",
      "user count: 15\n",
      "df length: 2535\n",
      "user count: 16\n",
      "df length: 2592\n",
      "user count: 17\n",
      "df length: 2865\n",
      "user count: 18\n",
      "df length: 2877\n",
      "user count: 19\n",
      "df length: 2941\n",
      "user count: 20\n",
      "df length: 3280\n",
      "user count: 21\n",
      "df length: 3533\n",
      "user count: 22\n",
      "df length: 4451\n",
      "user count: 23\n",
      "df length: 4726\n",
      "user count: 24\n",
      "df length: 5139\n",
      "user count: 25\n",
      "df length: 5209\n",
      "user count: 26\n",
      "df length: 5903\n",
      "user count: 27\n",
      "df length: 6130\n",
      "user count: 28\n",
      "df length: 6225\n",
      "user count: 29\n",
      "df length: 6546\n",
      "user count: 30\n",
      "df length: 6689\n",
      "user count: 31\n",
      "df length: 7627\n",
      "user count: 32\n",
      "df length: 8105\n",
      "user count: 33\n",
      "df length: 8167\n",
      "user count: 34\n",
      "df length: 8650\n",
      "user count: 35\n",
      "df length: 8679\n",
      "user count: 36\n",
      "df length: 8706\n",
      "user count: 37\n",
      "df length: 8727\n",
      "user count: 38\n",
      "df length: 8925\n",
      "user count: 39\n",
      "df length: 9078\n",
      "user count: 40\n",
      "df length: 9088\n",
      "user count: 41\n",
      "df length: 9216\n",
      "user count: 42\n",
      "df length: 9510\n",
      "user count: 43\n",
      "df length: 9544\n",
      "user count: 44\n",
      "df length: 9632\n",
      "user count: 45\n",
      "df length: 9727\n",
      "user count: 46\n",
      "df length: 10015\n",
      "user count: 47\n",
      "df length: 10290\n",
      "user count: 48\n",
      "df length: 10690\n",
      "user count: 49\n",
      "df length: 10779\n",
      "user count: 50\n",
      "df length: 11301\n",
      "user count: 51\n",
      "df length: 11402\n",
      "user count: 52\n",
      "df length: 11580\n",
      "user count: 53\n",
      "df length: 11962\n",
      "user count: 54\n",
      "df length: 12689\n",
      "user count: 55\n",
      "df length: 13407\n",
      "user count: 56\n",
      "df length: 13463\n",
      "user count: 57\n",
      "df length: 14229\n",
      "user count: 58\n",
      "df length: 14403\n",
      "user count: 59\n",
      "df length: 14486\n",
      "user count: 60\n",
      "df length: 14573\n",
      "user count: 61\n",
      "df length: 14603\n",
      "user count: 62\n",
      "df length: 14676\n",
      "user count: 63\n",
      "df length: 15196\n",
      "user count: 64\n",
      "df length: 15631\n",
      "user count: 65\n",
      "df length: 15898\n",
      "user count: 66\n",
      "df length: 16199\n",
      "user count: 67\n",
      "df length: 16577\n",
      "user count: 68\n",
      "df length: 16685\n",
      "user count: 69\n",
      "df length: 16698\n",
      "user count: 70\n",
      "df length: 16826\n",
      "user count: 71\n",
      "df length: 17181\n",
      "user count: 72\n",
      "df length: 17359\n",
      "user count: 73\n",
      "df length: 17661\n",
      "user count: 74\n",
      "df length: 17835\n",
      "user count: 75\n",
      "df length: 17840\n",
      "user count: 76\n",
      "df length: 17991\n",
      "user count: 77\n",
      "df length: 18021\n",
      "user count: 78\n",
      "df length: 18176\n",
      "user count: 79\n",
      "df length: 18497\n",
      "user count: 80\n",
      "df length: 18632\n",
      "user count: 81\n",
      "df length: 18737\n",
      "user count: 82\n",
      "df length: 18842\n",
      "user count: 83\n",
      "df length: 18986\n",
      "user count: 84\n",
      "df length: 19209\n",
      "user count: 85\n",
      "df length: 19505\n",
      "user count: 86\n",
      "df length: 19633\n",
      "user count: 87\n",
      "df length: 19906\n",
      "user count: 88\n",
      "df length: 20015\n",
      "user count: 89\n",
      "df length: 20436\n",
      "user count: 90\n",
      "df length: 20477\n",
      "user count: 91\n",
      "df length: 20541\n",
      "user count: 92\n",
      "df length: 21451\n",
      "user count: 93\n",
      "df length: 21574\n",
      "user count: 94\n",
      "df length: 21900\n",
      "user count: 95\n",
      "df length: 21977\n",
      "user count: 96\n",
      "df length: 22148\n",
      "user count: 97\n",
      "df length: 22272\n",
      "user count: 98\n",
      "df length: 22343\n",
      "user count: 99\n",
      "df length: 22472\n",
      "user count: 100\n",
      "df length: 22819\n",
      "user count: 101\n",
      "df length: 23104\n",
      "user count: 102\n",
      "df length: 23518\n",
      "user count: 103\n",
      "df length: 23703\n",
      "user count: 104\n",
      "df length: 23768\n",
      "user count: 105\n",
      "Saved: all_ss_comsubs_subscriptions_1113_1218.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'all_ss_comsubs_combined_.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w2/8h1csx0918l44bk67qghq0180000gn/T/ipykernel_5786/1801781540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Saved: all_ss_comsubs_subscriptions_{start}_{last_user}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdfall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_ss_comsubs_combined_.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#load combined csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mdfall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# concat to new df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all_ss_comsubs_combined_.csv'"
     ]
    }
   ],
   "source": [
    "#main\n",
    "df = pd.DataFrame()\n",
    "\n",
    "goal = start +300\n",
    "#get first response\n",
    "\n",
    "### set up for the wednesday\n",
    "for channelId in dfo.channelId[start:goal]:\n",
    "\n",
    "    try:    \n",
    "        if channelId not in df_combo.sub_channelId.unique(): # check to make sure this is a new sub_channelId\n",
    "            \n",
    "            response ,request, youtube = get_subcomms_subscriptions_first_response(channelId)\n",
    "            #turn first response to df\n",
    "            df = get_subscriber_ids(df,response)\n",
    "            print('df length: ' + str(len(df)))\n",
    "\n",
    "            df,request,response = get_subs_pagination(df=df,response=response ,request=request, youtube=youtube)\n",
    "            print(\"user count: \" +str(df.sub_channelId.nunique()))\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "last_user = df.sub_channelId.nunique() + start #create last user variable to use for name\n",
    "\n",
    "df.to_csv(f'all_ss_comsubs_subscriptions_{start}_{last_user}.csv',index=False) # save as csv\n",
    "print(f'Saved: all_ss_comsubs_subscriptions_{start}_{last_user}.csv') \n",
    "\n",
    "dfall = pd.read_csv('all_ss_comsubs_combined.csv',low_memory=False) #load combined csv\n",
    "dfall = pd.concat([dfall,df]) # concat to new df\n",
    "\n",
    "# save newly combined and print the number of unique users\n",
    "dfall.to_csv('all_ss_comsubs_combined.csv',index=False) ;print(f'total combined Uniques: '+ str(dfall.sub_channelId.nunique())) \n",
    "\n",
    "start=last_user #set up start for next time around\n",
    "print(f'start = {start}')\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total combined Uniques: 1076\n",
      "start = 1218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_kind</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>channel_description</th>\n",
       "      <th>channelId</th>\n",
       "      <th>sub_channelId</th>\n",
       "      <th>pageToken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23932</th>\n",
       "      <td>youtube#subscription</td>\n",
       "      <td>2022-01-19T10:59:31.21189Z</td>\n",
       "      <td>Aishwarya Srinivasan</td>\n",
       "      <td>Hi you! Thanks for stopping by on my channel.\\...</td>\n",
       "      <td>UCzd4ZN716evEjtbJERBMTfg</td>\n",
       "      <td>UCPQZDOCaogT1d_OfD167adA</td>\n",
       "      <td>CK8BEAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23933</th>\n",
       "      <td>youtube#subscription</td>\n",
       "      <td>2011-12-11T12:18:00Z</td>\n",
       "      <td>sciencecomedian</td>\n",
       "      <td>Earth's Premier Science Comedian, self-proclai...</td>\n",
       "      <td>UCzd6nZNHc0thJsUs-6XmZew</td>\n",
       "      <td>UCPQZDOCaogT1d_OfD167adA</td>\n",
       "      <td>CK8BEAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23934</th>\n",
       "      <td>youtube#subscription</td>\n",
       "      <td>2021-10-02T16:31:13.558398Z</td>\n",
       "      <td>Siksharthakam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UCze70Wozmq_2VzhrNbziSgg</td>\n",
       "      <td>UCPQZDOCaogT1d_OfD167adA</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              response_kind                  publishedAt  \\\n",
       "23932  youtube#subscription   2022-01-19T10:59:31.21189Z   \n",
       "23933  youtube#subscription         2011-12-11T12:18:00Z   \n",
       "23934  youtube#subscription  2021-10-02T16:31:13.558398Z   \n",
       "\n",
       "              channel_title  \\\n",
       "23932  Aishwarya Srinivasan   \n",
       "23933       sciencecomedian   \n",
       "23934         Siksharthakam   \n",
       "\n",
       "                                     channel_description  \\\n",
       "23932  Hi you! Thanks for stopping by on my channel.\\...   \n",
       "23933  Earth's Premier Science Comedian, self-proclai...   \n",
       "23934                                                NaN   \n",
       "\n",
       "                      channelId             sub_channelId pageToken  \n",
       "23932  UCzd4ZN716evEjtbJERBMTfg  UCPQZDOCaogT1d_OfD167adA   CK8BEAA  \n",
       "23933  UCzd6nZNHc0thJsUs-6XmZew  UCPQZDOCaogT1d_OfD167adA   CK8BEAA  \n",
       "23934  UCze70Wozmq_2VzhrNbziSgg  UCPQZDOCaogT1d_OfD167adA      none  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########\n",
    "## can delete now.  thisis in the cell above\n",
    "dfall = pd.read_csv('all_ss_comsubs_combined.csv',low_memory=False) #load combined csv\n",
    "dfall = pd.concat([dfall,df]) # concat to new df\n",
    "\n",
    "# save newly combined and print the number of unique users\n",
    "dfall.to_csv('all_ss_comsubs_combined.csv',index=False) ;print(f'total combined Uniques: '+ str(dfall.sub_channelId.nunique())) \n",
    "\n",
    "start=last_user #set up start for next time around\n",
    "print(f'start = {start}')\n",
    "df.tail(3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
